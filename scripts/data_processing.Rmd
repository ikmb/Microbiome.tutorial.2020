---
title: "Microbiome data processing"
author: "Malte Rühlemann (m.ruehlemann@ikmb.uni-kiel.de), Lucas Moitinho-Silva (l.silva@ikmb.uni-kiel.de)"
date: "12/14/2020"
output:
  rmarkdown::html_document:
  theme: cerulean
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.height = 6,
                      fig.width = 9, warning = F)
```
# Introduction and Objective 

## Sequencing reads and FastQ Format

The tutorial aims to give basic insights into microbial ecology using amplicons of the 16S rRNA gene for community description. As already mentioned in the in the lecture, the 16S rRNA gene is interesting, because it is available in all bacteria and arachaea (however not in fungi and other eukaryotes). Through its conserved regions, the 16S gene can be targeted across a wide range of organisms using universal primers. 

The variable regions of the 16S rRNA gene can function as a molecular clock, with more closely related microorganisms being more similar in their 16S rRNA sequence, enabling a fast and cheap method for community barcoding. Howver, 16S-based methods also have their pitfalls which one has to be aware of: taxon-specific amplificiation bias through mutations in primer binding sites or GC content or composition bias through variability in 16S rRNA copy numbers. However, in general 16S rRNA-based microbiome analysis is very reliable, reproducible and cost effective. 

In the second part of the tutorial, we will compare microbiome community differences between healthy individuals and people with inflammatory bowel disease (IBD). However, before we can do so, we need to process our sequencing data and get it into a format that enables us to analyze community composition. This tutorial is inspired by the [Bioconductor Workflow for Microbiome Data analyis](https://f1000research.com/articles/5-1492/v2), which provides also additional steps and details.

The data used in the tutorial is Illumina MiSeq sequencing data of the V1-V2 amplicon of the 16S rRNA gene. This data is usually handled and stored in FastQ format.  A FastQ File is composed of four lines per sequence: The Header, starting with an \@ Symbol followed by the sequence identifier, the Nucleotide Sequence, an additional comment line starting with \+ and the Per Base Quality:

    @SEQ1                                      # Header
    GATGAACGCTAGCGACAGGC                       # Sequence
    +                                          # Comment line
    9BCCCGGGGGGGGGGGGGGG                       # Per Base Quality 

As you can see, the Quality line contains letters, numbers and also symbols (`ASCII` code) which encode the sequence quality in the so called [Phred quality score](https://en.wikipedia.org/wiki/FASTQ_format#Encoding). Different encodings exist, however recent Illumina-based analysis usually use the Phred+33 or Q33 encoding, meaning the lowest quality score of 0 is encoded by the 33rd ASCII letter, which is the exlamation mark `!`, usually going up to a score of 40 (encoded as `I`) or 41 (`J`). 

Illumina sequencing is based on the so-called "sequencing-by-synthesis", where the incorporation of a nucleotide in the DNA sequence is read-out as optical signal by a camera, with different colors used for the different nucleotides used. These light signals can overlap, thus Quality Score _Q_ gives information on how "clean" a specific position could be read by the device and is defined by the error probability _p_ and the formula _Q_ = -10 _log_~10~ _p_. This is important for steps in data processing to which we will get later.

As our sequencing approach is based in the V1-V2 region of the 16S rRNA gene, we expect an amplicon size of \~312 base pairs (bp). Using the Illumina MiSeq, the data was generated using "Paired-End Reads", meaning that the amplicon was sequenced from both ends of the DNA fragments, resulting in two FastQ files per sample (called "Forward" and "Reverse", or "R1" and "R2"), in which each entry - called a "read" - represents a nucleotide sequence registered by the sequencing machine. These forward and reverse reads are in our case each 300bp long. Sequencing quality usually decreases after \~200bp, so even though it might seem unnecessary to sequence a 312bp amplicon with 2x300bp reads, this approach enables us to get very high quality sequencing data, something that is very important for amplicon-based microbiome analysis, as you will see later.

## ASVs, OTUs and Phylotypes

In today's tutorial, we will use the [DADA2](https://benjjneb.github.io/dada2/index.html) package for R to infer Amplicon Sequence Variants (ASVs; sometimes also called Ribosomal Sequence Variants/RSVs or zero OTUs/zOTUs), which means, we try to infer the exact amplicon sequence from the Illumina sequencing reads. The idea of using exact sequences is still rather new, as only a few years back (and actually still performed) sequencing quality was less reliable than it is today and computers were less powerful, but also databases of bacterial 16S rRNA sequences were much smaller, leading to the assumption, that clustering the less accurate sequencing data into so-called Operational Taxonomic Units (OTUs) at a universal level of 97\% similartiy will create community summaries of bacterial species. However, the growing database of microbial genomes and advances in data processing could clearly show, that this level of clustering is not sufficient, but that single nucleotide resolution is necessary (see [Edgar 2018](https://pubmed.ncbi.nlm.nih.gov/29506021/)). Together with increasing computational power and the development of new algorithms, this has now become the new standard in amplicon-based microbiome analysis.

After the inference of the ASV sequences, these can be classified using reference databases. Multiple of these database exist (e.g. [RDP](http://rdp.cme.msu.edu/), [SILVA](https://www.arb-silva.de/), and [GTDB](https://gtdb.ecogenomic.org/)), all of them have strengths and weaknesses and are constantly updated, growing together with newly discovered and sequenced microorganisms. However, independent of the used database, the annotation of 16S rRNA gene nucleotide sequences can be challenging and does not perform equally for all microbes, though usually genus-level annotation is possible for most sequences, thus this tutorial will focus mainly on this level (more on this later). 

This said, let's dive into the hands on part!

# Set work directory

Use the path that your folder scripts are on.
```{r}
getwd() # This tells you where you are, you are expected to be in the scripts folder. If not, you can set the working directory using a similar command as the commented line below.
#setwd("~/Desktop/microbiome/Microbiome.tutorial.2020-main/scripts")
```


# Load necessary libraries
```{r, message = F}
library(tidyverse) # Use of pipe and lots of functions for a better R coding
library(dada2) # Because we are going to process our sequencing data
```

# Get FastQ input files
```{r}
path="../data_raw/"

# list all files
fns <- list.files(path)

# keep only FastQ files
fastqs <- fns[grepl(".fastq.gz$", fns)]
fastqs <- sort(fastqs) # Sort ensures forward/reverse reads are in same order
### make sure that R1 is for forward read and R2 for reverse

fnFs <- fastqs[grepl("R1.fastq.gz", fastqs)] ## Just the forward read files
fnRs <- fastqs[grepl("R2.fastq.gz", fastqs)] ## Just the reverse read files

# Sample names are derived from the filenames
sample.names <- sapply(strsplit(fnFs, "_R1.fastq.gz"), `[`, 1)
cat(paste0("Starting processing for ",length(sample.names)," samples\n"))

## Fully specify the path for the fnFs and fnRs
fnFs_full <- file.path(path, fnFs)
fnRs_full <- file.path(path, fnRs)
```

# Quality profiles
```{r}
plotQualityProfile(c(fnFs_full[1:2],fnRs_full[1:2])) 
```

This plot summarizes the Quality Scores (y-Axis) by position (x-Axis, "Cycle") for the forward (R1; row 1) and reverse (R2, row 2) reads of the Samples "SAMPLE01" (column 1) and "SAMPLE02" (column 2). 

In gray-scale is a heat map of the frequency of each quality score at each base position. The mean quality score at each position is shown by the green line, and the quartiles of the quality score distribution by the orange lines. Let's look at the green line: for both samples we can see, that the forward read (top row) has high quality at the beginning, with the green line dropping below a Q value of 30 only around 250bp. In the bottom part of the plot, we can see that the green line start declining already much earlier, dropping below Q < 30 already before 200bp. This is very usual behavior for amplicon data, this is why we use the 2x300bp paired-end sequencing approach for this amplicon as stated earlier. 

# Trimming and filtering
```{r}
outdir=paste0("data")

### create folders for intermediate files
filt_path <- file.path(outdir, "filtered") # Place filtered files in filtered/ subdirectory
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sample.names, "_R_filt.fastq.gz"))

### perform the Trimming and Filtering
out <- filterAndTrim(fnFs_full, filtFs, fnRs_full, filtRs, 
                     truncLen=c(230,180),                               ### 
                     trimLeft=c(5, 5),                                  ###
                     maxN=0, maxEE=c(2,2), truncQ=5, rm.phix=TRUE,      ###
                     compress=TRUE,
                     multithread=4)                                     ###
```

The DADA2 package has convenient functions to perform all tasks, such the filtering and trimming of the sequencing data using `filterAndTrim()`. The filtering will take a few minutes. 

We specify some additional options:

* `truncLen=c(230,180)`: derived from the quality plots, we cut all forward reads after 230bp and all reverse reads after 180bp, keeping only high quality positions of the sequences.
* `trimLeft=c(5, 5)`: also from the left side (the beginning of the read), we cut 5bp.
* `maxN=0`: "N"s are unknown low-quality nucleotides, we remove all reads, where these are seen
* `maxEE=c(2,2)`: We remove all reads with an estimated error (EE) > 2, the estimated error is calculated from the quality scores of the read
* `truncQ=5`: if any nucleotide has a Q of 5 or lower, the read is truncated at this position
* `rm.phix=TRUE`: DNA of the Phage PhiX is added to the sequencing process due to technical reasons and are identified and discarded by this option
* `compress=TRUE`: The output is GZIP compressed to reduce filesize
* `multithread=4`: We are useing 4 CPUs in parallel to speed up teh process. 

Comparing plots of before and after filtering, we see that only high quality data remains, all bad quality sequencing output was removed. The red numbers show, how many of the original reads were kept. In a normal run, we expect between 10-20% of the reads to be discarded which still leaves us with tens of thousands of reads.

### Check reads after trimming
```{r}
plotQualityProfile(c(filtFs[1:2], fnFs_full[1:2]))
```

A much similar pattern can be seen for reverse reads, however it's also clearly visible that larger amounts of the reads were truncated

```{r}
plotQualityProfile(c(filtRs[1:2], fnRs_full[1:2]))
```

# Learning error rates
```{r}
## create output directory
dir.create(paste0(outdir,"/errors"),recursive=T,showWarnings=F)
## Learn forward error rates
errF <- learnErrors(filtFs, nbases=100000000, multithread=4)
saveRDS(errF, paste0(outdir,"/errors/errF.Rds"))

## Learn reverse error rates
errR <- learnErrors(filtRs, nbases=100000000, multithread=4)
saveRDS(errR, paste0(outdir,"/errors/errR.Rds"))

plotErrors(errR, nominalQ=TRUE)

```

This process is the centerpiece of the DADA2 package: learning the error rates. DADA2 uses a machine-learning algorithm and alternates between error estimation and inference of sample composition, thus it is tailored specifically to microbial ecology survey data. Using the quality scores, DADA2 infers how likely a specific error, e.g. that a C is read by the sequencer although there should be an A (A2C), in decency of the quality score in the FastQ file. This will allow DADA2 in the later steps to evaluate whether two ASVs are really different from each other, or if there has been a sequencing error and they actually are derived from the same biological sequence.

# Dereplication
```{r}
## Dereplicate the filtered fastq files
derepFs <- derepFastq(filtFs, verbose=FALSE)
derepRs <- derepFastq(filtRs, verbose=FALSE)

# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names
```

The dereplication simply reduces the sequencing data to unique forward and reverse sequences.

# Sequence inference
```{r}
dadaFs <- dada(derepFs, err=errF, multithread=4)
dadaRs <- dada(derepRs, err=errR, multithread=4)
```

This step is the second core function of DADA2: using the estimated error profiles and unique sequences it infers whether sequences are truly distinct biological entities or the same. Based on this, the true number of biological sequences per sample are identified.

# Sequence merging
```{r}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs)
```

And now after forward and reverse reads were cleaned, these need to be "stitched" together to form the complete amplicons. For overlapping regions (remember: the amplicon is \~312bp, thus there is large overlap between forward and reverse reads), again error profiles are utilized to distinguish errors from true divergence.

# Chimera identification
```{r}
seqtab <- makeSequenceTable(mergers)
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=4, verbose=TRUE)
print(sum(seqtab.nochim)/sum(seqtab))
```

In a final step, now the occurrence of each unique sequence in each sample is counted and written to a table with one row per sample and one column per sequence. This table now still contains chimeric sequences. These are sequences that really occur as output of the sequencing, however that are artefacts of the preceding PCR step prior to sequencing. As the 16S rRNA gene contains variable and constant/conserved stretches, it is possible that DNA fragments hybridize, which results in a sequence that is in part coming from each of the DNA molecules. 

Algorithms have been developed to identify these sequences by comparing them to the other (likely valid) sequences in each respective sample, without having to use external database. The resulting sequence-by-samples table is the final output of the amplicon sequence processing. The printed output shows, that although more than 50% of ASV sequences are identified as chimeric, only \~10\% of the total sequence counts are discarded, clearly showing that these sequences are rather low in abundance.

# QC Statistics 
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(mergers, getN), rowSums(seqtab), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoised", "merged", "tabled", "nonchim")
rownames(track) <- sample.names

p1 = track %>% data.frame %>% rownames_to_column("Sample") %>% gather(variable, value, -Sample) %>% 
  ggplot(aes(x=factor(variable, levels=colnames(track)), y=value, col=Sample, group=Sample)) + geom_point() + 
  geom_line() + xlab("QC Step") + ylab("Reads") + theme_bw()  + ylim(0,80000) 

p2 = track %>%  apply(., 1, function(x) x/x[1]) %>% t %>% data.frame %>% 
  rownames_to_column("Sample") %>% gather(variable, value, -Sample) %>% 
  ggplot(aes(x=factor(variable, levels=colnames(track)), y=value, col=Sample, group=Sample)) + geom_point(show.legend = F) + 
  geom_line(show.legend = F) + xlab("QC Step") + ylab("Proportion (%)") + ylim(0,1) + theme_bw()

gridExtra::grid.arrange(p1,p2, ncol=2, widths=c(.65,.35))
```
The two plots show the total number of read counts per sample after each QC step (left) and the relative amounts (right). 


# Taxonomic assignment

The assignment of taxonomic labels to the final ASV sequences is an important step, as these information can help make sense of the results for example by knowing that specific bacteria can perform specific metabolic functions. Also, taxonomic labels help to bin sequences together into larger phylogenetically related groups (meaning: groups that have a common ancestor at a given level of similarity), for example belonging to the same bacterial Phylum (very broad), Family (kind of similar), or even species or strain (very similar; many functions/genes are shared). As already mentioned, databases are still growing and newly discovered bacteria are constantly added to them, especially now as large-scale sequencing is widely available. This makes it especially hard to keep them up to date. Luckily, today we are working with samples from human stool samples, an environment which is widely studied and thus key members of the community are rather well-known and described.  

To make things a little easier, we will concentrate only on one sample for the taxonomic annotation step (you will get the complete dataset for the second part of the tutorial). The sample we'll be using is a so-called "Mock community", a mixture of genomic DNA from eight bacteria and two fungi. Equal amounts of genomic DNA (ng/µl) were used for each of the bacteria.

```{r}
seqtab.mock <- seqtab.nochim["ZyMOCK",seqtab.nochim["ZyMOCK",]>0, drop=F]

tax.mock <- data.frame(assignTaxonomy(seqtab.mock, "../taxonomy_db/rdp_train_set_16.fa.gz", multithread=4))

colnames(tax.mock) <- c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus")

tax.mock$seq = rownames(tax.mock)

rownames(tax.mock) <- colnames(seqtab.mock) <- paste0("ASV_",  sprintf("%03d", 1:nrow(tax.mock)))

dim(tax.mock)
```

The `assignTaxonomy()` function is a wrapper for a so-called "Bayesian Classifier". In brief, this classifier chops the ASV sequences into smaller parts and compares them to the database of sequences with know names (in our case the RDP Training Set 16). By doing this many times, the classifier can estimate the confidence of the assignment. If an assignment on Genus-level is possible, this means that in this database there is a known sequence which is likely coming from the same Genus as the sequence under investigation. It is also possible that the Genus-level annotation is not clear, maybe because the respective Genus is missing from the database, or the resolution of the chosen amplicon is not good enough to disentangle which Genus-level member of e.g. a bacterial family the sequence comes from. Let's have a look:

```{r}
print(tax.mock[is.na(tax.mock[,"Genus"]),])
```

These results may vary slightly from person to person, as there is always a little randomness in the data processing, however there are likely one or two sequences without assignments of Genus-level. Also it is likely that this sequence is classified on Family level as "Enterobacteriaceae". This bacterial family is know to not be highly resolved in V1-V2 sequencing.

Let's bin our sequences together on Genus level, to see how the Genera are distributed in the Mock Community:

```{r}
p3 = aggregate(. ~ tax.mock$Genus, data=data.frame(t(seqtab.mock)), FUN=sum) %>% data.frame(row.names = 1)  %>% 
  rownames_to_column("Tax") %>% 
  mutate(Abundance = 100*ZyMOCK/sum(ZyMOCK)) %>% 
  ggplot(aes(y=Abundance, x="MOCK", fill=Tax)) + geom_col(show.legend = F) + 
  scale_fill_brewer(palette="Paired") + ylab("Rel. Abundance (%)") + 
  scale_y_continuous(expand = c(0,0)) + theme_bw() + xlab("")

p4 = aggregate(. ~ tax.mock$Genus, data=data.frame(t(seqtab.mock)), FUN=sum) %>% data.frame(row.names = 1)  %>% 
  rownames_to_column("Tax") %>% mutate(Abundance = 100*ZyMOCK/sum(ZyMOCK)) %>% 
  ggplot(aes(y=Abundance, x=Tax, color=Tax)) + geom_point(size=5) + scale_color_brewer(palette="Paired") + 
  ylab("Rel. Abundance (%)") + scale_y_continuous(limits=c(0,20), expand = c(0,0)) +theme_bw() + 
  theme(axis.text.x = element_text(angle=45, hjust=1)) + geom_hline(yintercept = 12, lty=2, col="red")

gridExtra::grid.arrange(p3,p4, ncol=2, widths=c(.35,.65))

```

The left plot shows the community composition of the Mock community as stacked barplot, the right plot shows the same data, however separated by taxon. The horizontal red line shows the abundance value of 12\%, the percentage in which amount genomic DNA of all bacteria were added to the mock community. As you can see, some taxa are clearly above or below that line. Can you answer following questions:
* What could be reasons that abundances are not perfectly on the 12\% line?
* The community profile shows nine bacteria, however _Citrobacter_ is not part of the Mock community as sold by the vendor. How do you explain that it is found here?
* Two fungi ( _Saccharomyces cerevisiae_ and _Cryptococcus neoformans_) were also added to the Mock community. Why are these not found in the community profile?



# Session information
```{r}
sessionInfo()
```
